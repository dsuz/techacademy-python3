{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 【課題2】乳がんの腫瘍が良性か悪性かを予測する\n\n## 学習に使うデータセットをインポートする\n\nまずは課題の説明欄に記載したURLから腫瘍の計測データが入ったzipファイルをダウンロードし、解凍してください。\n表示された `breast_cancer_wisconsin_data.csv` ファイルを、Cloud9のワークスペース直下（このノートブックと同じディレクトリ）にアップロードします。\nアップロードが完了した状態で、下記のコードを実行して、画像のデータセットを読み込んでください。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# breast_cancer_wisconsin_data.csv を取り込む（命令を追記すること）\nimport pandas as pd\nbc_data = pd.read_csv(\"breast_cancer_wisconsin_data.csv\")\n\n# 先頭の5行のみ表示する（命令を追記すること）\nbc_data.head()",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>",
            "text/plain": "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0    842302         M        17.99         10.38          122.80     1001.0   \n1    842517         M        20.57         17.77          132.90     1326.0   \n2  84300903         M        19.69         21.25          130.00     1203.0   \n3  84348301         M        11.42         20.38           77.58      386.1   \n4  84358402         M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n0     ...               17.33           184.60      2019.0            0.1622   \n1     ...               23.41           158.80      1956.0            0.1238   \n2     ...               25.53           152.50      1709.0            0.1444   \n3     ...               26.50            98.87       567.7            0.2098   \n4     ...               16.67           152.20      1575.0            0.1374   \n\n   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n0             0.6656           0.7119                0.2654          0.4601   \n1             0.1866           0.2416                0.1860          0.2750   \n2             0.4245           0.4504                0.2430          0.3613   \n3             0.8663           0.6869                0.2575          0.6638   \n4             0.2050           0.4000                0.1625          0.2364   \n\n   fractal_dimension_worst  Unnamed: 32  \n0                  0.11890          NaN  \n1                  0.08902          NaN  \n2                  0.08758          NaN  \n3                  0.17300          NaN  \n4                  0.07678          NaN  \n\n[5 rows x 33 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "このCSVファイルには30以上の列があります。主要な列のみ、以下に概要を記載します。\n\n- id：連番\n- diagnosis：\"B\"か\"M\"の文字が格納されている（\"B\"：良性、\"M\"：悪性）\n- radius_mean：中心から外周までの平均距離（半径）\n- texture_mean：グレースケール（色の濃さ）の平均値\n- perimeter_mean：外周の平均の長さ\n\n今回は `radius_mean`（半径）を説明変数、`diagnosis`（良性か悪性か）を目的変数として回帰を行います。\n\n## \tインポートしたデータを計測データと教師データに分ける\n\n`radius_mean`列で測定データ `X`を、`diagnosis` 列で教師データ `y` を作成してください。また、DataFrame形式から ndarray 形式に変換しましょう。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# X と y を作成する（命令を追記すること）\nimport numpy as np\nX = np.array(bc_data.loc[:, [\"radius_mean\"]])\ny = np.array(bc_data.loc[:, [\"diagnosis\"]])\n# print(bc_data.loc[:, [\"radius_mean\"]])\nprint(X)\n\nX1 = bc_data.radius_mean\n# print(np.array(bc_data.radius_mean))\n# print(X1)\nX2 = np.array(X1)\nprint(np.array(X2))\nprint(X2)\n\n\nXX = []\nfor i in range(569):\n    XX.append([X2[i]])\n# print(XX)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[17.99 ]\n [20.57 ]\n [19.69 ]\n [11.42 ]\n [20.29 ]\n [12.45 ]\n [18.25 ]\n [13.71 ]\n [13.   ]\n [12.46 ]\n [16.02 ]\n [15.78 ]\n [19.17 ]\n [15.85 ]\n [13.73 ]\n [14.54 ]\n [14.68 ]\n [16.13 ]\n [19.81 ]\n [13.54 ]\n [13.08 ]\n [ 9.504]\n [15.34 ]\n [21.16 ]\n [16.65 ]\n [17.14 ]\n [14.58 ]\n [18.61 ]\n [15.3  ]\n [17.57 ]\n [18.63 ]\n [11.84 ]\n [17.02 ]\n [19.27 ]\n [16.13 ]\n [16.74 ]\n [14.25 ]\n [13.03 ]\n [14.99 ]\n [13.48 ]\n [13.44 ]\n [10.95 ]\n [19.07 ]\n [13.28 ]\n [13.17 ]\n [18.65 ]\n [ 8.196]\n [13.17 ]\n [12.05 ]\n [13.49 ]\n [11.76 ]\n [13.64 ]\n [11.94 ]\n [18.22 ]\n [15.1  ]\n [11.52 ]\n [19.21 ]\n [14.71 ]\n [13.05 ]\n [ 8.618]\n [10.17 ]\n [ 8.598]\n [14.25 ]\n [ 9.173]\n [12.68 ]\n [14.78 ]\n [ 9.465]\n [11.31 ]\n [ 9.029]\n [12.78 ]\n [18.94 ]\n [ 8.888]\n [17.2  ]\n [13.8  ]\n [12.31 ]\n [16.07 ]\n [13.53 ]\n [18.05 ]\n [20.18 ]\n [12.86 ]\n [11.45 ]\n [13.34 ]\n [25.22 ]\n [19.1  ]\n [12.   ]\n [18.46 ]\n [14.48 ]\n [19.02 ]\n [12.36 ]\n [14.64 ]\n [14.62 ]\n [15.37 ]\n [13.27 ]\n [13.45 ]\n [15.06 ]\n [20.26 ]\n [12.18 ]\n [ 9.787]\n [11.6  ]\n [14.42 ]\n [13.61 ]\n [ 6.981]\n [12.18 ]\n [ 9.876]\n [10.49 ]\n [13.11 ]\n [11.64 ]\n [12.36 ]\n [22.27 ]\n [11.34 ]\n [ 9.777]\n [12.63 ]\n [14.26 ]\n [10.51 ]\n [ 8.726]\n [11.93 ]\n [ 8.95 ]\n [14.87 ]\n [15.78 ]\n [17.95 ]\n [11.41 ]\n [18.66 ]\n [24.25 ]\n [14.5  ]\n [13.37 ]\n [13.85 ]\n [13.61 ]\n [19.   ]\n [15.1  ]\n [19.79 ]\n [12.19 ]\n [15.46 ]\n [16.16 ]\n [15.71 ]\n [18.45 ]\n [12.77 ]\n [11.71 ]\n [11.43 ]\n [14.95 ]\n [11.28 ]\n [ 9.738]\n [16.11 ]\n [11.43 ]\n [12.9  ]\n [10.75 ]\n [11.9  ]\n [11.8  ]\n [14.95 ]\n [14.44 ]\n [13.74 ]\n [13.   ]\n [ 8.219]\n [ 9.731]\n [11.15 ]\n [13.15 ]\n [12.25 ]\n [17.68 ]\n [16.84 ]\n [12.06 ]\n [10.9  ]\n [11.75 ]\n [19.19 ]\n [19.59 ]\n [12.34 ]\n [23.27 ]\n [14.97 ]\n [10.8  ]\n [16.78 ]\n [17.47 ]\n [14.97 ]\n [12.32 ]\n [13.43 ]\n [15.46 ]\n [11.08 ]\n [10.66 ]\n [ 8.671]\n [ 9.904]\n [16.46 ]\n [13.01 ]\n [12.81 ]\n [27.22 ]\n [21.09 ]\n [15.7  ]\n [11.41 ]\n [15.28 ]\n [10.08 ]\n [18.31 ]\n [11.71 ]\n [11.81 ]\n [12.3  ]\n [14.22 ]\n [12.77 ]\n [ 9.72 ]\n [12.34 ]\n [14.86 ]\n [12.91 ]\n [13.77 ]\n [18.08 ]\n [19.18 ]\n [14.45 ]\n [12.23 ]\n [17.54 ]\n [23.29 ]\n [13.81 ]\n [12.47 ]\n [15.12 ]\n [ 9.876]\n [17.01 ]\n [13.11 ]\n [15.27 ]\n [20.58 ]\n [11.84 ]\n [28.11 ]\n [17.42 ]\n [14.19 ]\n [13.86 ]\n [11.89 ]\n [10.2  ]\n [19.8  ]\n [19.53 ]\n [13.65 ]\n [13.56 ]\n [10.18 ]\n [15.75 ]\n [13.27 ]\n [14.34 ]\n [10.44 ]\n [15.   ]\n [12.62 ]\n [12.83 ]\n [17.05 ]\n [11.32 ]\n [11.22 ]\n [20.51 ]\n [ 9.567]\n [14.03 ]\n [23.21 ]\n [20.48 ]\n [14.22 ]\n [17.46 ]\n [13.64 ]\n [12.42 ]\n [11.3  ]\n [13.75 ]\n [19.4  ]\n [10.48 ]\n [13.2  ]\n [12.89 ]\n [10.65 ]\n [11.52 ]\n [20.94 ]\n [11.5  ]\n [19.73 ]\n [17.3  ]\n [19.45 ]\n [13.96 ]\n [19.55 ]\n [15.32 ]\n [15.66 ]\n [15.53 ]\n [20.31 ]\n [17.35 ]\n [17.29 ]\n [15.61 ]\n [17.19 ]\n [20.73 ]\n [10.6  ]\n [13.59 ]\n [12.87 ]\n [10.71 ]\n [14.29 ]\n [11.29 ]\n [21.75 ]\n [ 9.742]\n [17.93 ]\n [11.89 ]\n [11.33 ]\n [18.81 ]\n [13.59 ]\n [13.85 ]\n [19.16 ]\n [11.74 ]\n [19.4  ]\n [16.24 ]\n [12.89 ]\n [12.58 ]\n [11.94 ]\n [12.89 ]\n [11.26 ]\n [11.37 ]\n [14.41 ]\n [14.96 ]\n [12.95 ]\n [11.85 ]\n [12.72 ]\n [13.77 ]\n [10.91 ]\n [11.76 ]\n [14.26 ]\n [10.51 ]\n [19.53 ]\n [12.46 ]\n [20.09 ]\n [10.49 ]\n [11.46 ]\n [11.6  ]\n [13.2  ]\n [ 9.   ]\n [13.5  ]\n [13.05 ]\n [11.7  ]\n [14.61 ]\n [12.76 ]\n [11.54 ]\n [ 8.597]\n [12.49 ]\n [12.18 ]\n [18.22 ]\n [ 9.042]\n [12.43 ]\n [10.25 ]\n [20.16 ]\n [12.86 ]\n [20.34 ]\n [12.2  ]\n [12.67 ]\n [14.11 ]\n [12.03 ]\n [16.27 ]\n [16.26 ]\n [16.03 ]\n [12.98 ]\n [11.22 ]\n [11.25 ]\n [12.3  ]\n [17.06 ]\n [12.99 ]\n [18.77 ]\n [10.05 ]\n [23.51 ]\n [14.42 ]\n [ 9.606]\n [11.06 ]\n [19.68 ]\n [11.71 ]\n [10.26 ]\n [12.06 ]\n [14.76 ]\n [11.47 ]\n [11.95 ]\n [11.66 ]\n [15.75 ]\n [25.73 ]\n [15.08 ]\n [11.14 ]\n [12.56 ]\n [13.05 ]\n [13.87 ]\n [ 8.878]\n [ 9.436]\n [12.54 ]\n [13.3  ]\n [12.76 ]\n [16.5  ]\n [13.4  ]\n [20.44 ]\n [20.2  ]\n [12.21 ]\n [21.71 ]\n [22.01 ]\n [16.35 ]\n [15.19 ]\n [21.37 ]\n [20.64 ]\n [13.69 ]\n [16.17 ]\n [10.57 ]\n [13.46 ]\n [13.66 ]\n [11.08 ]\n [11.27 ]\n [11.04 ]\n [12.05 ]\n [12.39 ]\n [13.28 ]\n [14.6  ]\n [12.21 ]\n [13.88 ]\n [11.27 ]\n [19.55 ]\n [10.26 ]\n [ 8.734]\n [15.49 ]\n [21.61 ]\n [12.1  ]\n [14.06 ]\n [13.51 ]\n [12.8  ]\n [11.06 ]\n [11.8  ]\n [17.91 ]\n [11.93 ]\n [12.96 ]\n [12.94 ]\n [12.34 ]\n [10.94 ]\n [16.14 ]\n [12.85 ]\n [17.99 ]\n [12.27 ]\n [11.36 ]\n [11.04 ]\n [ 9.397]\n [14.99 ]\n [15.13 ]\n [11.89 ]\n [ 9.405]\n [15.5  ]\n [12.7  ]\n [11.16 ]\n [11.57 ]\n [14.69 ]\n [11.61 ]\n [13.66 ]\n [ 9.742]\n [10.03 ]\n [10.48 ]\n [10.8  ]\n [11.13 ]\n [12.72 ]\n [14.9  ]\n [12.4  ]\n [20.18 ]\n [18.82 ]\n [14.86 ]\n [13.98 ]\n [12.87 ]\n [14.04 ]\n [13.85 ]\n [14.02 ]\n [10.97 ]\n [17.27 ]\n [13.78 ]\n [10.57 ]\n [18.03 ]\n [11.99 ]\n [17.75 ]\n [14.8  ]\n [14.53 ]\n [21.1  ]\n [11.87 ]\n [19.59 ]\n [12.   ]\n [14.53 ]\n [12.62 ]\n [13.38 ]\n [11.63 ]\n [13.21 ]\n [13.   ]\n [ 9.755]\n [17.08 ]\n [27.42 ]\n [14.4  ]\n [11.6  ]\n [13.17 ]\n [13.24 ]\n [13.14 ]\n [ 9.668]\n [17.6  ]\n [11.62 ]\n [ 9.667]\n [12.04 ]\n [14.92 ]\n [12.27 ]\n [10.88 ]\n [12.83 ]\n [14.2  ]\n [13.9  ]\n [11.49 ]\n [16.25 ]\n [12.16 ]\n [13.9  ]\n [13.47 ]\n [13.7  ]\n [15.73 ]\n [12.45 ]\n [14.64 ]\n [19.44 ]\n [11.68 ]\n [16.69 ]\n [12.25 ]\n [17.85 ]\n [18.01 ]\n [12.46 ]\n [13.16 ]\n [14.87 ]\n [12.65 ]\n [12.47 ]\n [18.49 ]\n [20.59 ]\n [15.04 ]\n [13.82 ]\n [12.54 ]\n [23.09 ]\n [ 9.268]\n [ 9.676]\n [12.22 ]\n [11.06 ]\n [16.3  ]\n [15.46 ]\n [11.74 ]\n [14.81 ]\n [13.4  ]\n [14.58 ]\n [15.05 ]\n [11.34 ]\n [18.31 ]\n [19.89 ]\n [12.88 ]\n [12.75 ]\n [ 9.295]\n [24.63 ]\n [11.26 ]\n [13.71 ]\n [ 9.847]\n [ 8.571]\n [13.46 ]\n [12.34 ]\n [13.94 ]\n [12.07 ]\n [11.75 ]\n [11.67 ]\n [13.68 ]\n [20.47 ]\n [10.96 ]\n [20.55 ]\n [14.27 ]\n [11.69 ]\n [ 7.729]\n [ 7.691]\n [11.54 ]\n [14.47 ]\n [14.74 ]\n [13.21 ]\n [13.87 ]\n [13.62 ]\n [10.32 ]\n [10.26 ]\n [ 9.683]\n [10.82 ]\n [10.86 ]\n [11.13 ]\n [12.77 ]\n [ 9.333]\n [12.88 ]\n [10.29 ]\n [10.16 ]\n [ 9.423]\n [14.59 ]\n [11.51 ]\n [14.05 ]\n [11.2  ]\n [15.22 ]\n [20.92 ]\n [21.56 ]\n [20.13 ]\n [16.6  ]\n [20.6  ]\n [ 7.76 ]]\n[17.99  20.57  19.69  11.42  20.29  12.45  18.25  13.71  13.    12.46\n 16.02  15.78  19.17  15.85  13.73  14.54  14.68  16.13  19.81  13.54\n 13.08   9.504 15.34  21.16  16.65  17.14  14.58  18.61  15.3   17.57\n 18.63  11.84  17.02  19.27  16.13  16.74  14.25  13.03  14.99  13.48\n 13.44  10.95  19.07  13.28  13.17  18.65   8.196 13.17  12.05  13.49\n 11.76  13.64  11.94  18.22  15.1   11.52  19.21  14.71  13.05   8.618\n 10.17   8.598 14.25   9.173 12.68  14.78   9.465 11.31   9.029 12.78\n 18.94   8.888 17.2   13.8   12.31  16.07  13.53  18.05  20.18  12.86\n 11.45  13.34  25.22  19.1   12.    18.46  14.48  19.02  12.36  14.64\n 14.62  15.37  13.27  13.45  15.06  20.26  12.18   9.787 11.6   14.42\n 13.61   6.981 12.18   9.876 10.49  13.11  11.64  12.36  22.27  11.34\n  9.777 12.63  14.26  10.51   8.726 11.93   8.95  14.87  15.78  17.95\n 11.41  18.66  24.25  14.5   13.37  13.85  13.61  19.    15.1   19.79\n 12.19  15.46  16.16  15.71  18.45  12.77  11.71  11.43  14.95  11.28\n  9.738 16.11  11.43  12.9   10.75  11.9   11.8   14.95  14.44  13.74\n 13.     8.219  9.731 11.15  13.15  12.25  17.68  16.84  12.06  10.9\n 11.75  19.19  19.59  12.34  23.27  14.97  10.8   16.78  17.47  14.97\n 12.32  13.43  15.46  11.08  10.66   8.671  9.904 16.46  13.01  12.81\n 27.22  21.09  15.7   11.41  15.28  10.08  18.31  11.71  11.81  12.3\n 14.22  12.77   9.72  12.34  14.86  12.91  13.77  18.08  19.18  14.45\n 12.23  17.54  23.29  13.81  12.47  15.12   9.876 17.01  13.11  15.27\n 20.58  11.84  28.11  17.42  14.19  13.86  11.89  10.2   19.8   19.53\n 13.65  13.56  10.18  15.75  13.27  14.34  10.44  15.    12.62  12.83\n 17.05  11.32  11.22  20.51   9.567 14.03  23.21  20.48  14.22  17.46\n 13.64  12.42  11.3   13.75  19.4   10.48  13.2   12.89  10.65  11.52\n 20.94  11.5   19.73  17.3   19.45  13.96  19.55  15.32  15.66  15.53\n 20.31  17.35  17.29  15.61  17.19  20.73  10.6   13.59  12.87  10.71\n 14.29  11.29  21.75   9.742 17.93  11.89  11.33  18.81  13.59  13.85\n 19.16  11.74  19.4   16.24  12.89  12.58  11.94  12.89  11.26  11.37\n 14.41  14.96  12.95  11.85  12.72  13.77  10.91  11.76  14.26  10.51\n 19.53  12.46  20.09  10.49  11.46  11.6   13.2    9.    13.5   13.05\n 11.7   14.61  12.76  11.54   8.597 12.49  12.18  18.22   9.042 12.43\n 10.25  20.16  12.86  20.34  12.2   12.67  14.11  12.03  16.27  16.26\n 16.03  12.98  11.22  11.25  12.3   17.06  12.99  18.77  10.05  23.51\n 14.42   9.606 11.06  19.68  11.71  10.26  12.06  14.76  11.47  11.95\n 11.66  15.75  25.73  15.08  11.14  12.56  13.05  13.87   8.878  9.436\n 12.54  13.3   12.76  16.5   13.4   20.44  20.2   12.21  21.71  22.01\n 16.35  15.19  21.37  20.64  13.69  16.17  10.57  13.46  13.66  11.08\n 11.27  11.04  12.05  12.39  13.28  14.6   12.21  13.88  11.27  19.55\n 10.26   8.734 15.49  21.61  12.1   14.06  13.51  12.8   11.06  11.8\n 17.91  11.93  12.96  12.94  12.34  10.94  16.14  12.85  17.99  12.27\n 11.36  11.04   9.397 14.99  15.13  11.89   9.405 15.5   12.7   11.16\n 11.57  14.69  11.61  13.66   9.742 10.03  10.48  10.8   11.13  12.72\n 14.9   12.4   20.18  18.82  14.86  13.98  12.87  14.04  13.85  14.02\n 10.97  17.27  13.78  10.57  18.03  11.99  17.75  14.8   14.53  21.1\n 11.87  19.59  12.    14.53  12.62  13.38  11.63  13.21  13.     9.755\n 17.08  27.42  14.4   11.6   13.17  13.24  13.14   9.668 17.6   11.62\n  9.667 12.04  14.92  12.27  10.88  12.83  14.2   13.9   11.49  16.25\n 12.16  13.9   13.47  13.7   15.73  12.45  14.64  19.44  11.68  16.69\n 12.25  17.85  18.01  12.46  13.16  14.87  12.65  12.47  18.49  20.59\n 15.04  13.82  12.54  23.09   9.268  9.676 12.22  11.06  16.3   15.46\n 11.74  14.81  13.4   14.58  15.05  11.34  18.31  19.89  12.88  12.75\n  9.295 24.63  11.26  13.71   9.847  8.571 13.46  12.34  13.94  12.07\n 11.75  11.67  13.68  20.47  10.96  20.55  14.27  11.69   7.729  7.691\n 11.54  14.47  14.74  13.21  13.87  13.62  10.32  10.26   9.683 10.82\n 10.86  11.13  12.77   9.333 12.88  10.29  10.16   9.423 14.59  11.51\n 14.05  11.2   15.22  20.92  21.56  20.13  16.6   20.6    7.76 ]\n[17.99  20.57  19.69  11.42  20.29  12.45  18.25  13.71  13.    12.46\n 16.02  15.78  19.17  15.85  13.73  14.54  14.68  16.13  19.81  13.54\n 13.08   9.504 15.34  21.16  16.65  17.14  14.58  18.61  15.3   17.57\n 18.63  11.84  17.02  19.27  16.13  16.74  14.25  13.03  14.99  13.48\n 13.44  10.95  19.07  13.28  13.17  18.65   8.196 13.17  12.05  13.49\n 11.76  13.64  11.94  18.22  15.1   11.52  19.21  14.71  13.05   8.618\n 10.17   8.598 14.25   9.173 12.68  14.78   9.465 11.31   9.029 12.78\n 18.94   8.888 17.2   13.8   12.31  16.07  13.53  18.05  20.18  12.86\n 11.45  13.34  25.22  19.1   12.    18.46  14.48  19.02  12.36  14.64\n 14.62  15.37  13.27  13.45  15.06  20.26  12.18   9.787 11.6   14.42\n 13.61   6.981 12.18   9.876 10.49  13.11  11.64  12.36  22.27  11.34\n  9.777 12.63  14.26  10.51   8.726 11.93   8.95  14.87  15.78  17.95\n 11.41  18.66  24.25  14.5   13.37  13.85  13.61  19.    15.1   19.79\n 12.19  15.46  16.16  15.71  18.45  12.77  11.71  11.43  14.95  11.28\n  9.738 16.11  11.43  12.9   10.75  11.9   11.8   14.95  14.44  13.74\n 13.     8.219  9.731 11.15  13.15  12.25  17.68  16.84  12.06  10.9\n 11.75  19.19  19.59  12.34  23.27  14.97  10.8   16.78  17.47  14.97\n 12.32  13.43  15.46  11.08  10.66   8.671  9.904 16.46  13.01  12.81\n 27.22  21.09  15.7   11.41  15.28  10.08  18.31  11.71  11.81  12.3\n 14.22  12.77   9.72  12.34  14.86  12.91  13.77  18.08  19.18  14.45\n 12.23  17.54  23.29  13.81  12.47  15.12   9.876 17.01  13.11  15.27\n 20.58  11.84  28.11  17.42  14.19  13.86  11.89  10.2   19.8   19.53\n 13.65  13.56  10.18  15.75  13.27  14.34  10.44  15.    12.62  12.83\n 17.05  11.32  11.22  20.51   9.567 14.03  23.21  20.48  14.22  17.46\n 13.64  12.42  11.3   13.75  19.4   10.48  13.2   12.89  10.65  11.52\n 20.94  11.5   19.73  17.3   19.45  13.96  19.55  15.32  15.66  15.53\n 20.31  17.35  17.29  15.61  17.19  20.73  10.6   13.59  12.87  10.71\n 14.29  11.29  21.75   9.742 17.93  11.89  11.33  18.81  13.59  13.85\n 19.16  11.74  19.4   16.24  12.89  12.58  11.94  12.89  11.26  11.37\n 14.41  14.96  12.95  11.85  12.72  13.77  10.91  11.76  14.26  10.51\n 19.53  12.46  20.09  10.49  11.46  11.6   13.2    9.    13.5   13.05\n 11.7   14.61  12.76  11.54   8.597 12.49  12.18  18.22   9.042 12.43\n 10.25  20.16  12.86  20.34  12.2   12.67  14.11  12.03  16.27  16.26\n 16.03  12.98  11.22  11.25  12.3   17.06  12.99  18.77  10.05  23.51\n 14.42   9.606 11.06  19.68  11.71  10.26  12.06  14.76  11.47  11.95\n 11.66  15.75  25.73  15.08  11.14  12.56  13.05  13.87   8.878  9.436\n 12.54  13.3   12.76  16.5   13.4   20.44  20.2   12.21  21.71  22.01\n 16.35  15.19  21.37  20.64  13.69  16.17  10.57  13.46  13.66  11.08\n 11.27  11.04  12.05  12.39  13.28  14.6   12.21  13.88  11.27  19.55\n 10.26   8.734 15.49  21.61  12.1   14.06  13.51  12.8   11.06  11.8\n 17.91  11.93  12.96  12.94  12.34  10.94  16.14  12.85  17.99  12.27\n 11.36  11.04   9.397 14.99  15.13  11.89   9.405 15.5   12.7   11.16\n 11.57  14.69  11.61  13.66   9.742 10.03  10.48  10.8   11.13  12.72\n 14.9   12.4   20.18  18.82  14.86  13.98  12.87  14.04  13.85  14.02\n 10.97  17.27  13.78  10.57  18.03  11.99  17.75  14.8   14.53  21.1\n 11.87  19.59  12.    14.53  12.62  13.38  11.63  13.21  13.     9.755\n 17.08  27.42  14.4   11.6   13.17  13.24  13.14   9.668 17.6   11.62\n  9.667 12.04  14.92  12.27  10.88  12.83  14.2   13.9   11.49  16.25\n 12.16  13.9   13.47  13.7   15.73  12.45  14.64  19.44  11.68  16.69\n 12.25  17.85  18.01  12.46  13.16  14.87  12.65  12.47  18.49  20.59\n 15.04  13.82  12.54  23.09   9.268  9.676 12.22  11.06  16.3   15.46\n 11.74  14.81  13.4   14.58  15.05  11.34  18.31  19.89  12.88  12.75\n  9.295 24.63  11.26  13.71   9.847  8.571 13.46  12.34  13.94  12.07\n 11.75  11.67  13.68  20.47  10.96  20.55  14.27  11.69   7.729  7.691\n 11.54  14.47  14.74  13.21  13.87  13.62  10.32  10.26   9.683 10.82\n 10.86  11.13  12.77   9.333 12.88  10.29  10.16   9.423 14.59  11.51\n 14.05  11.2   15.22  20.92  21.56  20.13  16.6   20.6    7.76 ]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "さて、`y` には \"B\" もしくは \"M\" という文字データが入っています。数値化した方がコンピュータは学習しやすくなるので、データの前処理のひとつ「カテゴリの数値化」を実行しましょう。カテゴリの数値化をするには `LabelEncoder` というものを利用します。\n\n[sklearn.preprocessing.LabelEncoder - scikit-learn 0.19 documentation](http://scikit-learn.org/0.19/modules/generated/sklearn.preprocessing.LabelEncoder.html)\n\n※ `LabelEncoder` は、ここまでのレッスンの内容では登場しませんでしたので、以下のコードをそのまま実行いただければ大丈夫です。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# カテゴリの数値化\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit([\"B\", \"M\"])                         # 良性：0, 悪性：1\ny = le.transform(y.flatten())\n\n# 数値化した状態を確認してみる\nprint(y)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1\n 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0\n 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0\n 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1\n 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0\n 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0\n 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1\n 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0\n 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1\n 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 1 1 1 1 1 1 0]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## \tデータを訓練データとテストデータに分ける\n\n`X` および `y` を訓練データとテストデータに分けましょう。その際、訓練データ8割、テストデータ2割としてください。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 訓練データ8割、テストデータ2割に分割する（命令を追記すること）\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 訓練データを用いて予測モデルを作成する\n\n今までの回帰プログラムでは線形分析を利用しました。線形回帰は、ボストンの住宅価格で描いたような直線のグラフになります。\n\nしかし今回は **ロジスティック回帰** を利用します。\n\n[ロジスティック回帰 - Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%AD%E3%82%B8%E3%82%B9%E3%83%86%E3%82%A3%E3%83%83%E3%82%AF%E5%9B%9E%E5%B8%B0)\n\nロジスティック回帰は以下の赤線のようなグラフを描くため、`y` が2つの値しか存在しない場合に利用すると良い精度が得られます。\n\n![ml_14.png](https://techacademy.s3.amazonaws.com/bootcamp/python/machine-learning/ml_14.png)\n\nロジスティック回帰は `LogisticRegression` クラスを利用します。使い方は線形回帰の `LinearRegression` と同じです。コンストラクタで回帰モデルのオブジェクトを作成し、訓練データを指定して `fit()` を実行します。より詳しい情報は公式ドキュメントを参照してください。\n\n[sklearn.linear_model.LogisticRegression - scikit-learn 0.19 documentation](http://scikit-learn.org/0.19/modules/generated/sklearn.linear_model.LogisticRegression.html)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ロジスティック回帰の回帰モデルを作成する\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\n\n# 訓練データを回帰モデルに設定する（命令を追記すること）\nmodel.fit(X_train, y_train)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## テストデータを回帰モデルに当てはめて予測を実施する\n\nこの回帰モデルを使って予測を実行しましょう。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 予測を実行する（命令を追記すること）\ny_pred = model.predict(X_test)",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 結果を表示する\n\nまずは、予測値と実際の値をそのまま表示してください。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 予測値を表示する（命令を追記すること）\nprint(y_pred)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1\n 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0\n 0 1 0]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 実際の値を表示する（命令を追記すること）\nprint(y_test)",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1\n 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0\n 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0\n 0 1 0]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "この機械学習は回帰ではありますが、分類に近いところがありますので、予測の精度を混合行列で示したり、正答率を表示したりすることができます。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 混合行列で集計結果を表示する（命令を追記すること）\nfrom sklearn import metrics\nprint(metrics.confusion_matrix(y_test, y_pred))",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[70  2]\n [12 30]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 正答率を表示する（命令を追記すること）\nprint(metrics.classification_report(y_test, y_pred))",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "             precision    recall  f1-score   support\n\n          0       0.85      0.97      0.91        72\n          1       0.94      0.71      0.81        42\n\navg / total       0.88      0.88      0.87       114\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "最後にグラフを表示してみましょう。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ロジスティック回帰のグラフを描くために必要な関数と処理。ここの内容は変更しない！\ndef logit(x, lr):\n    return x * lr.coef_ + lr.intercept_\n\ndef p(x, lr):\n    return 1 / (1 + np.exp(-logit(x, lr)))\n\nimport math\nX_test_min = math.floor(np.min(X_test))\nX_test_max = math.ceil(np.max(X_test))",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\n\n# テストデータを青色の散布図として表示する（命令を追記すること）\nplt.scatter(X_test, y_test, color = \"blue\")\n\n# ロジスティック回帰の曲線グラフを赤色の線で表示する。ここの内容は変更しない！\nX_plot = np.arange(X_test_min, X_test_max)\nplt.plot(X_plot, p(X_plot, model).flatten(), color = \"red\")",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "[<matplotlib.lines.Line2D at 0x7f198c939668>]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<matplotlib.figure.Figure at 0x7f198d0c0a20>"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}